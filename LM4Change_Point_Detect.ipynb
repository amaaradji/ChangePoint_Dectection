{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KP4Bq3mjFJ9M",
    "outputId": "d75d6a6d-f09d-4ba0-bd0c-f1009ed1356c"
   },
   "outputs": [],
   "source": [
    "#To execute on Google Colab\n",
    "# !pip install pm4py\n",
    "# !wget https://data.4tu.nl/ndownloader/files/24025820\n",
    "# !mv 24025820 BPI_Challenge_2018.xes.gz\n",
    "# !gzip -d BPI_Challenge_2018.xes.gz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sbGJWucoE_vu"
   },
   "outputs": [],
   "source": [
    "from pm4py.objects.log.importer.xes import importer as xes_importer\n",
    "import pm4py\n",
    "import time\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.utils import plot_model \n",
    "import tensorflow.keras.utils as ku \n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "from pm4py.algo.filtering.log.timestamp import timestamp_filter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66,
     "referenced_widgets": [
      "c3fa1eb268f341c08a2f7cca8eb7ee57",
      "6f87f521ab7a43a1aa42edd489bd4d12",
      "fd5948d148164cb480922f23dd195a83",
      "deedc11bfa214b7d8af2bcbde5587804",
      "c330d3cb007c40b7a2e6c4f062959440",
      "2f97699a619e49bbb59251dbc6bb2dd3",
      "c9cdfa0b2d4c4bd0862d2689d63052f4",
      "05616f62e810457da3be04afc0462238"
     ]
    },
    "id": "iidCxyLEE_vx",
    "outputId": "aae15a9c-8472-4f90-a1f9-0b8bc4a6c925"
   },
   "outputs": [],
   "source": [
    "# log = xes_importer.apply('filtered_log.xes')\n",
    "# log = xes_importer.apply('financial_log-filtered-5.xes')\n",
    "# log = xes_importer.apply('SuncorpSkin.xes')\n",
    "log = xes_importer.apply('BPI_Challenge_2018.xes')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YYXj8HJgE_vz",
    "outputId": "0f23fb8d-1865-4599-f4e8-d8d908b35954"
   },
   "outputs": [],
   "source": [
    "sizes_dict = {}\n",
    "for i in range(len(log)):\n",
    "    k = len(log[i])\n",
    "    if k in sizes_dict:\n",
    "        v = sizes_dict[k] \n",
    "        sizes_dict[k] = v + 1\n",
    "    else:\n",
    "        sizes_dict[k] = 1\n",
    "print(sizes_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4Zlj1VH2E_vz",
    "outputId": "a39e08c3-40bf-4554-ebca-37b5ca4c9749"
   },
   "outputs": [],
   "source": [
    "print('Number of actions: ', len(sizes_dict))\n",
    "print('Number of examples: ', len(log))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5turGfCFcFvJ"
   },
   "outputs": [],
   "source": [
    "vocab_index = {}\n",
    "for seq in log:\n",
    "    for action in seq:\n",
    "        action_name = action['concept:name']\n",
    "        if not action_name in vocab_index:\n",
    "            v = len(vocab_index) + 1\n",
    "            vocab_index[action_name] = v    \n",
    "total_words = len(vocab_index) + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WSN8VUHvE_v0",
    "outputId": "db0fc65f-1eab-4385-c012-89183206662d"
   },
   "outputs": [],
   "source": [
    "def get_data_with_filter(filtered_log, time_s, time_e):\n",
    "  timestamp_s = datetime.timestamp(datetime.strptime(time_s, '%Y-%m-%d %H:%M:%S'))\n",
    "  timestamp_e = datetime.timestamp(datetime.strptime(time_e, '%Y-%m-%d %H:%M:%S'))\n",
    "  input_sequences = []\n",
    "  for seq in filtered_log:\n",
    "      sequence = []\n",
    "      timestamp = 0.0\n",
    "      for action in seq:\n",
    "          action_name = action['concept:name']        \n",
    "          action_index = vocab_index[action_name]\n",
    "          timestamp = datetime.timestamp(action[\"time:timestamp\"])\n",
    "          if timestamp >= timestamp_s and timestamp <= timestamp_e: \n",
    "            sequence.append((action_index, timestamp)) \n",
    "      if len(sequence) != 0: \n",
    "        sequence.sort(key=lambda x: x[1], reverse=False)\n",
    "        \n",
    "        sequence = [x[0] for x in sequence]     \n",
    "        for i in range(1, len(sequence)):\n",
    "                input_sequences.append(sequence[:i+1])          \n",
    "  return input_sequences\n",
    "\n",
    "\n",
    "input_sequences_train = get_data_with_filter(log, \"2015-12-09 00:00:00\", \"2017-01-1 00:00:00\")\n",
    "input_sequences_val = get_data_with_filter(log, \"2017-01-1 00:00:01\", \"2017-03-1 00:00:00\")\n",
    "input_sequences_test = get_data_with_filter(log, \"2017-03-1 00:00:00\", \"2018-01-19 23:59:59\")\n",
    "\n",
    "print('Training size = ', len(input_sequences_train))\n",
    "print('Val size = ', len(input_sequences_val))\n",
    "print('Test size = ', len(input_sequences_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "id": "b2xeBHHcHajs",
    "outputId": "f092ab0e-9d9a-4336-a71f-07d54eecc49b"
   },
   "outputs": [],
   "source": [
    "size_dist = []\n",
    "for seq in input_sequences_train:\n",
    "    size_dist.append(len(seq))\n",
    "\n",
    "sns.histplot(size_dist)\n",
    "plt.xlabel('Size')\n",
    "plt.ylabel('#of examples')\n",
    "# plt.xlim(0,200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dxb4VS3DHt0L"
   },
   "outputs": [],
   "source": [
    "max_sequence_len = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9__RwCXgE_v0",
    "outputId": "f65a6f32-d97f-48d3-9c5a-3e22dae0ea45"
   },
   "outputs": [],
   "source": [
    "sample = 20\n",
    "reverse_vocab_index = dict(map(reversed, vocab_index.items()))\n",
    "print(\"The entry \",sample,\" in 'input_sequences' is: \")\n",
    "print(input_sequences_train[sample])\n",
    "print(\" and it corresponds to:\")\n",
    "for i in input_sequences_train[sample]:\n",
    "    print(reverse_vocab_index[i], end=' ')\n",
    "                        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QYxFa20sE_v1"
   },
   "source": [
    "Next, we padd our training set to the max length in order to be able to make a batch processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gxCxunViE_v1"
   },
   "outputs": [],
   "source": [
    "# max_sequence_len = max([len(x) for x in input_sequences])\n",
    "input_sequences_train = np.array(pad_sequences(input_sequences_train, maxlen=max_sequence_len, padding='pre'))\n",
    "input_sequences_val = np.array(pad_sequences(input_sequences_val, maxlen=max_sequence_len, padding='pre'))\n",
    "input_sequences_test = np.array(pad_sequences(input_sequences_test, maxlen=max_sequence_len, padding='pre'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QPPLUOa5E_v1"
   },
   "source": [
    "Run the following to see the containt of the padded 'input_sequences' object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HxML76xIE_v1",
    "outputId": "32931bc9-6fd5-4ac1-a4c3-f6e40a40dab2"
   },
   "outputs": [],
   "source": [
    "print(\"The entry \",sample,\" in 'input_sequences' is: \")\n",
    "print(input_sequences_train[sample])\n",
    "print(\" and it corresponds to:\")\n",
    "print(\"[\", end=' ')\n",
    "for i in input_sequences_train[sample]:\n",
    "    if i in reverse_vocab_index:\n",
    "        print(reverse_vocab_index[i], end=' ')\n",
    "    else:\n",
    "        print(\"__\", end=' ')\n",
    "print(\"]\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_UMH9qNlE_v2"
   },
   "source": [
    "Given a sentence like **\"A B A C\"**, we want to design a model that can predict the next action -- in the case the action **\"C\"**.\n",
    "\n",
    "Therefore, the next code prepares our input and output to our model consequently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rGwupW70E_v2"
   },
   "outputs": [],
   "source": [
    "input_to_model_train, label_train = input_sequences_train[:,:-1],input_sequences_train[:,-1]\n",
    "input_to_model_val, label_val = input_sequences_val[:,:-1],input_sequences_val[:,-1]\n",
    "input_to_model_test, label_test = input_sequences_test[:,:-1],input_sequences_test[:,-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P4vvAMzwE_v2",
    "outputId": "c37f99ea-072c-4bbd-c591-dcbd9b44e666"
   },
   "outputs": [],
   "source": [
    "print(\"The entry \",sample,\" in 'input_sequences' is: \")\n",
    "print(input_sequences_train[sample])\n",
    "print(\", it corresponds to the following input to our model:\")\n",
    "print(input_to_model_train[sample])\n",
    "print(\" and the following output: \", label_train[sample])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kNsNz3NbE_v3"
   },
   "source": [
    "Here is the architecture of the model we will use:\n",
    "\n",
    "<img src=\"https://github.com/amaaradji/ChangePoint_Dectection/blob/main/imgs/text_generation.png?raw=1\" style=\"width:600;height:400px;\">\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "np3clNTHE_v3"
   },
   "source": [
    " \n",
    "**Exercise**: Implement `model()`. You will need to carry out 5 steps:\n",
    "\n",
    "1. Create a sequencial model using the `Sequential` class\n",
    "2. Add an embedding layer to the model using the `Embedding` class of size 128\n",
    "3. Add an LSTM layer to the model using the `LSTM` class of size 128\n",
    "4. Add a Dense layer to the model using the `Dense` class with a `softmax` activation\n",
    "5. Set a `categorical_crossentropy` loss function to the model and optimize `accuracy`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 738
    },
    "id": "vddbWFkrE_v3",
    "outputId": "4ca51106-1a22-43b9-eaf7-610946dc31f9"
   },
   "outputs": [],
   "source": [
    "def create_model(dropout_value):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(total_words, 64, input_length=max_sequence_len-1))\n",
    "    model.add(Bidirectional(LSTM(128, return_sequences=False, recurrent_dropout=dropout_value)))\n",
    "    # model.add(Bidirectional(LSTM(128, recurrent_dropout=dropout_value)))\n",
    "    model.add(Dropout(dropout_value))\n",
    "    model.add(Dense(total_words, activation='softmax'))\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(learning_rate=0.01), metrics=['accuracy'])\n",
    "    return model\n",
    "    \n",
    "# #Print details of the model.\n",
    "model = create_model(0.2)\n",
    "model.summary()\n",
    "plot_model(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Wu38d0bJE_v4",
    "outputId": "9b83508f-b3c2-4296-9248-4c6fb24cbe1d"
   },
   "outputs": [],
   "source": [
    "tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "tf.config.experimental_connect_to_cluster(tpu)\n",
    "tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "# Create model\n",
    "with strategy.scope():\n",
    "    model = create_model(0.5)\n",
    "\n",
    "\n",
    "history = model.fit(input_to_model_train, label_train, \n",
    "                    validation_data=(input_to_model_val,label_val), \n",
    "                    epochs=10, \n",
    "                    batch_size=256, \n",
    "                    verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fJPPdzGvE_v5"
   },
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.figure(figsize=(15,4))\n",
    "\n",
    "ax1 = plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, loss, label='Training loss')\n",
    "plt.plot(epochs, val_loss, label='Validation loss')\n",
    "plt.fill_between(epochs, loss,val_loss,color='g',alpha=.1)\n",
    "\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "ax2 = plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, acc, label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, label='Validation accuracy')\n",
    "plt.fill_between(epochs, acc,val_acc,color='g',alpha=.1)\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UXMCafn1E_v5"
   },
   "outputs": [],
   "source": [
    "test_set = []\n",
    "step = 10000\n",
    "\n",
    "for i in range(0,len(input_to_model_test), step):\n",
    "    if i+step > len(input_to_model_test):\n",
    "            break\n",
    "    x_test = input_to_model_test[i:i+step] \n",
    "    y_test = label_test[i:i+step] \n",
    "    test_set.append((x_test, y_test))\n",
    "      \n",
    "    \n",
    "accuracy_list = []\n",
    "with tqdm(total=len(test_set)) as pbar:\n",
    "  for x_test,y_test in test_set:\n",
    "      accuracy_list.append(model.evaluate(x_test, y_test, batch_size=256, verbose=0)[1])\n",
    "      pbar.update(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gY1OUs3rE_v5"
   },
   "outputs": [],
   "source": [
    "N = 10\n",
    "cumsum, moving_aves = [0], []\n",
    "\n",
    "for i, x in enumerate(accuracy_list, 1):\n",
    "    cumsum.append(cumsum[i-1] + x)\n",
    "    if i >= N:\n",
    "        moving_ave = (cumsum[i] - cumsum[i-N])/N\n",
    "        #can do stuff with moving_ave here\n",
    "        moving_aves.append(moving_ave)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R84fKODeE_v6"
   },
   "outputs": [],
   "source": [
    "plt.plot(list(range(len(accuracy_list))), accuracy_list, label='Accuracy')\n",
    "plt.plot(list(range(len(moving_aves))), moving_aves, label='Accuracy MA')\n",
    "plt.xlabel('Window')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nkj-k-VJP4Zo",
    "outputId": "09da5bc1-3e50-457f-81b3-7386037f940f"
   },
   "outputs": [],
   "source": [
    "print(input_sequences_unsorted[0][1])\n",
    "print(input_sequences_unsorted[-1][1])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "machine_shape": "hm",
   "name": "LM4Change_Point_Detect.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "05616f62e810457da3be04afc0462238": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2f97699a619e49bbb59251dbc6bb2dd3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6f87f521ab7a43a1aa42edd489bd4d12": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c330d3cb007c40b7a2e6c4f062959440": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "c3fa1eb268f341c08a2f7cca8eb7ee57": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_fd5948d148164cb480922f23dd195a83",
       "IPY_MODEL_deedc11bfa214b7d8af2bcbde5587804"
      ],
      "layout": "IPY_MODEL_6f87f521ab7a43a1aa42edd489bd4d12"
     }
    },
    "c9cdfa0b2d4c4bd0862d2689d63052f4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "deedc11bfa214b7d8af2bcbde5587804": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_05616f62e810457da3be04afc0462238",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_c9cdfa0b2d4c4bd0862d2689d63052f4",
      "value": " 43809/43809 [03:54&lt;00:00, 186.71it/s]"
     }
    },
    "fd5948d148164cb480922f23dd195a83": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "parsing log, completed traces :: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2f97699a619e49bbb59251dbc6bb2dd3",
      "max": 43809,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c330d3cb007c40b7a2e6c4f062959440",
      "value": 43809
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
